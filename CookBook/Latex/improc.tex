\section{Image processing and information extraction}\label{sec:improc}

\subsection{Simple calculus with channels}\label{ssec:calculus}

The \application{BandMath} application provides a simple and efficient
way to perform band operations. The command line application and the
corresponding Monteverdi module (shown in the section \ref{Band_math module})
are based on the same standards. It computes a band wise operation according
to a user defined mathematical expression. The following code computes the
absolute difference between first bands of two images:

\begin{verbatim}
otbcli_BandMath -il input_image_1 input_image_2
                -exp "abs(im1b1 - im2b1)"
                -out output_image
\end{verbatim}

The naming convention "im[x]b[y]" designates the yth band of the xth input image.

The \application{BandMath} application embeds built-in operators and functions
(listed \href{http://muparser.sourceforge.net/mup_features.html#idDef2}{here}),
allowing a vast choice of possible operations.

\subsection{Segmentation}\label{ssec:segmentation}

Segmenting objects across a very high resolution scene and with a controlled
quality is a difficult task for which no method has reached a sufficient level
of performance to be considered as operational.

Even if we leave aside the question of segmentation quality and
consider that we have a method performing reasonably well on our data
and objects of interest, the task of scaling up segmentation to real
very high resolution data is itself challenging. First, we can not
load the whole data into memory, and there is a need for on the flow
processing which does not cope well with traditional segmentation
algorithms. Second, the result of the segmentation process
itself is difficult to represent and manipulate efficiently.

The experience of segmenting large remote sensing images is packed into a single
\application{Segmentation} in \app.

You can find more information about this application
\href{http://blog.orfeo-toolbox.org/preview/coming-next-large-scale-segmentation}{here}.


%\subsection{Segmentation}\label{ssec:segmentation}
%todo.

%\subsection{Change detection}\label{ssec:changedetection}
%todo.

%\subsection{Object-based image analysis}\label{ssec:obia}
%todo.

\subsection{Dempster Shafer based Classifier Fusion}\label{ssec:classifierfusion}

This framework is dedicated to perform cartographic validation starting
from the result of a detection (for example a road extraction), enhance
the results fiability by using a classifier fusion algorithm. Using a
set of descriptor, the processing chain validates or invalidates the
input geometrical features.

% \subsubsection{Prequel: Road Extraction}
%
% The first step of this recipe is to produce an interesting and adapted
% input. The \application{otbRoadExtractionApplication},  included in
% \app , provides a set of geometrical features that can be used as input of the following process. This is only an example, the Dempster-Shafer framework was not designed specifically to be used with otbRoadExtractionApplication but it is a good example of what the input should be like.

\subsubsection{Fuzzy Model (requisite)}

The \application{DSFuzzyModelEstimation} application performs the fuzzy
model estimation (once by use case: descriptor set / Belief support /
Plausibility support). It has the following input parameters :
\begin{itemize}
\item \verb?-psin? a vector data of positive samples enriched according to the
"Compute Descriptors" part
\item \verb?-nsin? a vector data of negative samples enriched according to the
"Compute Descriptors" part
\item \verb?-belsup? a support for the Belief computation
\item \verb?-plasup? a support for the Plausibility computation
\item \verb?-desclist? an initialization model (xml file) or a descriptor name list
(listing the descriptors to be included in the model)
\end{itemize}

The application can be used like this:
\begin{verbatim}
otbcli_DSFuzzyModelEstimation -psin     PosSamples.shp
                              -nsin     NegSamples.shp
                              -belsup   "ROADSA"
                              -plasup   "NONDVI" "ROADSA" "NOBUIL"
                              -desclist "NONDVI" "ROADSA" "NOBUIL"
                              -out      FuzzyModel.xml
\end{verbatim}

The output file \verb?FuzzyModel.xml? contains the optimal model to perform
informations fusion.

\subsubsection{First Step: Compute Descriptors}

The first step in the classifier fusion based validation is to compute, for
each studied polyline, the choosen descriptors. In this context, the
\application{ComputePolylineFeatureFromImage} application can be used for a
large range of descriptors. It has the following inputs :
\begin{itemize}
\item \verb?-in? an image (of the sudied scene) corresponding to the choosen
descriptor (NDVI, building Mask\dots)
\item \verb?-vd? a vector data containing polyline of interest
\item \verb?-expr? a formula ("b1 \textgreater 0.4", "b1 == 0") where b1 is
the standard name of input image first band
\item \verb?-field? a field name corresponding to the descriptor codename
(NONDVI, ROADSA...)
\end{itemize}

The output is a vector data containing polylines with a new field containing
the descriptor value. In order to add the "NONDVI" descriptor to an input
vector data ("inVD.shp") corresponding to the percentage of pixels along a
polyline that verifies the formula "NDVI \textgreater 0.4" :

\begin{verbatim}
otbcli_ComputePolylineFeatureFromImage -in   NDVI.TIF
                                       -vd  inVD.shp
                                       -expr  "b1 > 0.4"
                                       -field "NONDVI"
                                       -out   VD_NONDVI.shp
\end{verbatim}

\verb?NDVI.TIF? is the NDVI mono band image of the studied scene.
This step must be repeated for each choosen descriptor:

\begin{verbatim}
otbcli_ComputePolylineFeatureFromImage -in   roadSpectralAngle.TIF
                                       -vd  VD_NONDVI.shp
                                       -expr  "b1 > 0.24"
                                       -field "ROADSA"
                                       -out   VD_NONDVI_ROADSA.shp
\end{verbatim}

\begin{verbatim}
otbcli_ComputePolylineFeatureFromImage -in   Buildings.TIF
                                       -vd  VD_NONDVI_ROADSA.shp
                                       -expr  "b1 == 0"
                                       -field "NOBUILDING"
                                       -out   VD_NONDVI_ROADSA_NOBUIL.shp
\end{verbatim}

Both \verb?NDVI.TIF? and \verb?roadSpectralAngle.TIF? can be produced
using \mont feature extraction capabilities, and \verb?Buildings.TIF?
can be generated using \mont rasterization module. From now on,
\verb?VD_NONDVI_ROADSA_NOBUIL.shp? contains three descriptor fields.
It will be used in the following part.

\subsubsection{Second Step: Feature Validation}

The final application (\application{VectorDataDSValidation}) will
validate or unvalidate the studied samples using
\href{http://en.wikipedia.org/wiki/Dempster\%E2\%80\%93Shafer_theory}{the Dempster-Shafer theory}
. Its inputs are :
\begin{itemize}
\item \verb?-in? an enriched vector data "VD\_NONDVI\_ROADSA\_NOBUIL.shp"
\item \verb?-belsup? a support for the Belief computation
\item \verb?-plasup? a support for the Plausibility computation
\item \verb?-descmod? a fuzzy model FuzzyModel.xml
\end{itemize}
The output is a vector data containing only the validated samples.

\begin{verbatim}
otbcli_VectorDataDSValidation -in      extractedRoads_enriched.shp
                              -descmod FuzzyModel.xml
                              -out     validatedSamples.shp
\end{verbatim}

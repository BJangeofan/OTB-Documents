** Learning and classification from pixels                        :classpix:
*** Description
**** Abstract

     This exercise will get you familiar with the OTB pixel based
     classification applications. You will learn how to train a SVM
     classification model from Pleiades images and a set of training
     regions. You will then learn how to apply this model to images
     and produce shiny classification maps.

**** Data
     If you need to generate the data ~melbourne_ms_toa_ortho_extract_small.tif~
     used in this exercise from the
     original products (Bundle MS), you can use the following command lines.

     To orthorectify the MS product:

     #+LATEX:\begin{tiny}
     #+BEGIN_SRC bash
     $ otbcli_OrthoRectification \
    -io.in FCGC600031035/IMG_PHR1A_MS_002/IMG_PHR1A_MS_201202250025599_SEN_PRG_FC_5847-002_R1C1.JP2 
    -io.out ~/temporary/ortho_phr_ms_small.tif uint16 -outputs.mode auto -outputs.ulx 313892 
    -outputs.uly 5816639 -outputs.spacingx 2 -outputs.spacingy -2 -opt.ram 1024 -map utm 
    -map.utm.zone 55 -outputs.sizex  2048 -outputs.sizey 2048  -map.utm.northhem 0
     #+END_SRC
     #+LATEX:\end{tiny}

     To convert pixel values in top of atmosphere milli-reflectance:

     #+LATEX:\begin{tiny}
     #+BEGIN_SRC bash
     $ otbcli_OpticalCalibration \
       -in ~/temporary/ortho_phr_ms_small.tif 
       -out melbourne_ms_toa_ortho_extract_small.tif uint16 -milli 1 -level toa
     #+END_SRC
     #+LATEX:\end{tiny}

     You can also generate also the ~melbourne_ms_toa_ortho_extract_large.tif~
     with the same set of commands. You just need to change the size of the
     orthorectify region to 4096 instead of 2048. 
     
**** Pre-requisites
     
     - Basic knowledge on OTB applications and QGIS usage
     - Basic knowledge on image supervised classification
     - Basic knowledge on GIS vector file formats

**** Achievements

     - Usage of the OTB Classification applications
     - Classification of large images
     - Import of results in a GIS software

*** Steps

    In this part of the exercise, you will use the following data:

    ~melbourne_ms_toa_ortho_extract_small.tif~

**** Produce and analyze learning samples

     - Use QGIS to produce polygons for 5 classes (vegetation, roads, soil, buildings and water)
     - Export this vector layer in ESRI Shapefile (.shp). Other OGR format can
       also be used here.
     - What is the label corresponding to the class *water* in the
       shapefile?  An example set of learning samples is provided for
       the exercise in /training.shp/

     _Tips and Recommendations:_
      - Note the field name of the shapefile which contains the label. You will
        need to provide this field in the training application

**** Estimate image statistics

     In order to make these features comparable between each images,
     the first step is to estimate the input images statistics. These
     statistics will be used to center and reduce the intensities
     (mean of 0 and standard deviation of 1) of training samples from
     the vector data produced by the user.

     - Use the *ComputeImagesStatistics* to compute statistics on
       the image
     - What is the mean of the red band?
     - The extract provided has been converted from DN to
       milli-reflectance. For what reasons, is it advised to do so
       when performing multiple images classification?

**** Estimate classification model using the Support Vector Machine algorithm
     
     The *TrainImagesClassifier* application performs supervised
     classifier training from multiple pairs of input images and
     training vector data. Samples are composed of pixel values in
     each band optionally centered and reduced using XML statistics
     file produced by the *ComputeImagesStatistics* application. We will
     use this application with only one image in this exercise.
     - How many classifiers are available in the  *TrainImagesClassifier* application?
     - Use the *TrainImagesClassifier* to produce SVM model
     - Which kernel is used by default in the application?
     - What is the measured accuracy?
     - Use the *TrainImagesClassifier* to produce Random Forests model

**** Apply classification model
     - Use the *ImageClassifier* to apply the classification model (SVM and RF) to the input image
     - What is the output of the application?
     - Bonus : Use the same model to apply the classification to the other extract
 
       ~melbourne_ms_toa_ortho_extract_large.tif~

**** Produce printable classification map
     We are now going to produce a printable classification map using the
     *ColorMapping* application This tool will replace each label with an 8-bits
     RGB color specified in a mapping file.  The mapping file should look like
     this :
     
     : $ # Lines beginning with a # are ignored
     : 1 255 0 0

     - Produce your custom look-up table (LUT)
     - Use this LUT to produce a printable classification map for both classifier (in PNG format)
     - Overlay this map on the input image in QGIS. Comment on the classification results.
     - 

**** Classification map regularization

     Resulting classification maps can be regularized in order to smoothen
     irregular classes. Such a regularization process improves classification
     results by making more homogeneous areas which are easier to handle.

     - What is the application which allows to perform classification map regularization?
     - What is the purpose of the boolean parameter /suvbool/?
     - Perform classification map regularization using the output of the
       *ImageClassifier* application?
**** Fusion of classification maps

     After having processed several classifications of the same input image but
     from different models or methods (SVM, KNN, Random Forest,...), it is
     possible to make a fusion of these classification maps. The Fusion of
     Classifications generates a single more robust and precise classification
     map which combines the information extracted from the input list of labeled
     images.
     - What application should be use to perform fusion of classification maps?
     - How many algorithms are available in the application?
     - Perform fusion of the 2 classification map using DS algorithm (fused SVM
       and RF classification maps)

**** Homework

     - Produce classification model with different kind of SVM
       kernels and try other machine learning algorithms available. Comment different accuracies obtained?
     - Going big: Apply this classification on the pan-sharpened image over Melbourne
       
*** Solutions                                            :classpix:solutions:
**** Produce and analyze learning samples

     The label corresponding to the *water* class in the shapefile is *2*

**** Estimate image statistics
      
     Here is the command line to produce the image statistics:

     : $ otbcli_ComputeImagesStatistics 
     :   -il melbourne_ms_toa_ortho_extract_small.tif 
     :   -out melbourne_ms_toa_ortho_extract_small_stats.xml

     # #+HEADERS: :tangle yes  :var cmdpath="/home/grizonnetm/local/bin/otbApplicationLauncherCommandLine"
     # #+begin_src sh
     # export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$HOME/local/lib:$HOME/local/lib/otb
     # $cmdpath ComputeImagesStatistics /home/grizonnetm/local/lib/otb/applications  -out /media/grizonnetm/MANU_LINUX/OTB_Courses/test.xml -il /media/grizonnetm/MANU_LINUX/OTB_Courses/Exercises/ex3_classif_pixel/melbourne_ms_toa_ortho_extract_small.tif
     # #+end_src

     # #+RESULTS:
     # : Processing Image (1/1): 0% [                                                  ]Processing Image (1/1): 2% [*                                                 ]Processing Image (1/1): 4% [**                                                ]Processing Image (1/1): 6% [***                                               ]Processing Image (1/1): 8% [****                                              ]Processing Image (1/1): 10% [*****                                             ]Processing Image (1/1): 12% [******                                            ]Processing Image (1/1): 14% [*******                                           ]Processing Image (1/1): 16% [********                                          ]Processing Image (1/1): 18% [*********                                         ]Processing Image (1/1): 20% [**********                                        ]Processing Image (1/1): 22% [***********                                       ]Processing Image (1/1): 24% [************                                      ]Processing Image (1/1): 26% [*************                                     ]Processing Image (1/1): 28% [**************                                    ]Processing Image (1/1): 30% [***************                                   ]Processing Image (1/1): 32% [****************                                  ]Processing Image (1/1): 34% [*****************                                 ]Processing Image (1/1): 36% [******************                                ]Processing Image (1/1): 38% [*******************                               ]Processing Image (1/1): 40% [********************                              ]Processing Image (1/1): 42% [*********************                             ]Processing Image (1/1): 44% [**********************                            ]Processing Image (1/1): 46% [***********************                           ]Processing Image (1/1): 48% [************************                          ]Processing Image (1/1): 50% [*************************                         ]Processing Image (1/1): 52% [**************************                        ]Processing Image (1/1): 54% [***************************                       ]Processing Image (1/1): 56% [****************************                      ]Processing Image (1/1): 58% [*****************************                     ]Processing Image (1/1): 60% [******************************                    ]Processing Image (1/1): 62% [*******************************                   ]Processing Image (1/1): 64% [********************************                  ]Processing Image (1/1): 66% [*********************************                 ]Processing Image (1/1): 68% [**********************************                ]Processing Image (1/1): 70% [***********************************               ]Processing Image (1/1): 72% [************************************              ]Processing Image (1/1): 74% [*************************************             ]Processing Image (1/1): 76% [**************************************            ]Processing Image (1/1): 78% [***************************************           ]Processing Image (1/1): 80% [****************************************          ]Processing Image (1/1): 82% [*****************************************         ]Processing Image (1/1): 84% [******************************************        ]Processing Image (1/1): 86% [*******************************************       ]Processing Image (1/1): 88% [********************************************      ]Processing Image (1/1): 90% [*********************************************     ]Processing Image (1/1): 92% [**********************************************    ]Processing Image (1/1): 94% [***********************************************   ]Processing Image (1/1): 96% [************************************************  ]Processing Image (1/1): 98% [************************************************* ]Processing Image (1/1): 100% [**************************************************] (0.4 seconds)

     
#     #+INCLUDE: "/media/grizonnetm/MANU_LINUX/OTB_Courses/test.xml"

     The value of the mean of the red band is *111.625*. Reflectance
     allows to compare radiometric values between images of different
     sensors.

**** Estimate classification model using the Support Vector Machine algorithm

     This application is based on LibSVM and on OpenCV Machine Learning
     classifiers, and is compatible with OpenCV 2.3.1 and later.
     
     There is currently 9 algorithms available.

     Here is the command line to produce the SVM model (default algorithm used
     by the application):

     : $ otbcli_TrainImagesClassifier 
     :   -io.il melbourne_ms_toa_ortho_extract_small.tif 
     :   -io.imstat melbourne_ms_toa_ortho_extract_small_stats.xml 
     :   -io.vd training.shp 
     :   -io.out melbourne_ms_toa_ortho_extract_small_model.svm

     Linear kernel is used by default in the application. The measured
     accuracy is around 0.9. The value is high due to the low number of
     training samples and their lack of variability.

**** Apply classification model
     
     Here is the command line to produce the SVM model:
     : $ otbcli_ImageSVMClassifier 
     :   -in melbourne_ms_toa_ortho_extract_small.tif 
     :   -model melbourne_ms_toa_ortho_extract_small_model.svm 
     :   -imstat melbourne_ms_toa_ortho_extract_small_stats.xml 
     :   -out melbourne_extract_small_classification_5classes.tif 
     :   uint8
     Pixels of the output image will contain the class label decided by
     the SVM classifier.
**** Produce printable classification map

    The look-up table (LUT) used to produce the classification map in my case is:

#+INCLUDE: "Images/ColorTable.txt" src

    Here is the command line to produce the classification map:

    : $ ColorMapping 
    :   -in melbourne_extract_small_classification_5classes.tif 
    :   -out melbourne_extract_small_classification_color.png uint8 
    :   -method custom -method.custom.lut ColorTable.txt

    And the result of the command:

    #+Latex:\vspace{0.5cm}
     #+Latex:\begin{center}
     #+ATTR_LaTeX: width=0.45\textwidth
     [[file:Images/melbourne_ms_toa_ortho_extract_small_classification_5classes_color_mapping.png]]
     #+Latex:\end{center}
     #+Latex:\vspace{0.5cm}

**** Classification map regularization

***** Item 1
      The application is the *ClassificationMapRegularization*.
***** Item 2
      The *FusionOfClassifications* application uses either majority voting or
      the Demspter Shafer framework to handle this fusion.
***** Item 3

      Here is the command line to produce the fusion of classification maps:

    : $ FusionOfClassifications
    :   -il cmap1.tif cmap2.tif  
    :   -out melbourne_extract_small_classification_fused.tif
    :   -method majorityvoting  
    :   -nodatalabel    0  
    :   -undecidedlabel 10  

**** Fusion of classification

***** Item 1
      The application is the *FusionOfClassifications*.
***** Item 2

      The boolean parameter /suvbool/ used to choose whether pixels with more than one
      majority class are set to Undecided (true), or to their Original labels
      (false = default value). Please note that the Undecided value must be
      different from existing labels in the input image
***** Item 3

      Here is the command line to produce the classification map:

    : $ ClassificationMapRegularization
    :   -io.in melbourne_extract_small_classification_5classes.tif 
    :   -io.out melbourne_extract_small_classification_regul.png uint8
    :   -ip.radius          3  
    :   -ip.suvbool         true  
    :   -ip.nodatalabel     10  
    :   -ip.undecidedlabel  7 

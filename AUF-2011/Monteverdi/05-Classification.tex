\documentclass[compress]{beamer}
\mode<presentation>
{
 \usetheme{Vilanova}
}

\usepackage[french]{babel}

\usepackage[utf8]{inputenc}

\usepackage{times}
\usepackage[T1]{fontenc}

\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{tikz}
\usepackage{eurosym}
%\usepackage{url}
\usepackage[normal]{subfigure}
\newcommand{\goodgap}{%
	\hspace{\subfigtopskip}%
	\hspace{\subfigbottomskip}}



%\newtheorem{definition}{Definition}

\title{Extraction de primitives}




\author
{jordi.inglada@cesbio.cnes.fr}
\normalsize

\institute[Cesbio] % (optional, but mostly needed)
{\textsc{Centre d'Études Spatiales de la Biosphère, Toulouse, France}}

\date{}

\pgfdeclareimage[height=96mm,width=128mm]{background}{fondsClairSansLogo}
\setbeamertemplate{background}{\pgfuseimage{background}}
\pgfdeclareimage[height=0.6cm]{logoIncrust}{logoIncrust}
\pgfdeclareimage[height=0.5cm]{logo_cesbio}{logo_cesbio}
\logo{
\begin{tabular}{lp{0.25\textwidth}lp{0.25\textwidth}r}
\href{http://www.cesbio.ups-tlse.fr/}{\pgfuseimage{logo_cesbio}}
&&\footnotesize{AUF - Marrakech 2011}&&
\href{http://www.orfeo-toolbox.org}{\pgfuseimage{logoIncrust}}\\
\end{tabular}
}


\subject{Extraction de primitives}




% Delete this, if you do not want the table of contents to pop up at
% the beginning of each subsection:
\AtBeginSubsection[]
{
  \begin{frame}<beamer>
    \frametitle{Outline}
    \tableofcontents[currentsection,currentsubsection]
  \end{frame}
}




% If you wish to uncover everything in a step-wise fashion, uncomment
% the following command: 

%\beamerdefaultoverlayspecification{<+->}
\begin{document}

\begin{frame}
  \titlepage
  \begin{center}
{\tiny Ce contenu est dérivé de la formation \href{http://www.orfeo-toolbox.org/packages/PragmaticRemoteSensing-handout.pdf}{``Pragmatic Remote
  Sensing''} dispensée par J. Inglada et E. Christophe en juillet 2010
  dans le cadre du colloque IGARSS. Il est mis à disposition selon les termes de la licence :\\
Creative Commons Paternité – Partage à l’Identique 3.0 non transcrit.} \href{http://creativecommons.org/licenses/by-sa/3.0/}{\includegraphics[width=0.05\textwidth]{/home/inglada/Dev/GH/IGARSS2010/Tutorial/Slides/Ressources/CC-licence.png}}    
  \end{center}
\end{frame}


\section[Intro]{La classification d'images}
\begin{frame}
\frametitle{La classification d'images}
  \begin{itemize}
  \item Définition : procédure par laquelle on attibue une étiquette
    aux objets (pixels de l'image)
  \item Supervisée
  \item Non-supervisée
  \item Orientée pixel
  \item Orientée objet
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Données pour la classification}
  \begin{itemize}
  \item Images (réflectances)
  \item Primitives
    \begin{itemize}
    \item Indices radiométriques: NDVI, brillance, couleur, angle
      spectral, etc.
    \item Statistiques, textures, etc.
    \item Transformatiosn: ACP, MNF, ondelettes, etc.
    \end{itemize}
  \item Données exogènes
    \begin{itemize}
    \item MNT, cartes, etc.
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{La classification en 4 étapes}
  \begin{itemize}
  \item Sélection des attributs pertinents (primitives, etc.)
  \item Création d'un vecteur d'attributs par pixel
  \item Choix de l'étiquette de la classe (dans le cas supervisé)
  \item Apprentissage du classifieur
  \end{itemize}
\end{frame}
\section[Non-supervisé]{Classification non-supervisée}
\label{sec:unsupervised}
\begin{frame}
\frametitle{Classification non-supervisée}
  \begin{itemize}
  \item Aussi appelée {\em clustering}
  \item Nécessite une interprétation des résultats (reconnaissance des
    classes)
    \begin{itemize}
    \item Les étiquettes des classes sont des nombres (1, 2, ...)
    \end{itemize}
  \item Pas besoin de vérité terrain ou d'exemples
    \begin{itemize}
    \item Le nombre de classes est souvent choisi à la main
    \item Autres paramètres sont aussi nécessaires
    \end{itemize}
  \item Exemples: k-moyennes, ISO-Data, carte de Kohonen
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Exemple: K-moyenens}
\setbeamercovered{invisible}

{\tiny
  \begin{center}
    \begin{tabular}{lc}
     \onslide<2->{1. k initial "means" are randomly} &\\
\onslide<2->{selected from the data set.}&\\
&\onslide<2->{\includegraphics[width=0.15\textwidth]{kmeans_step1.pdf}}\\
     \onslide<3->{2. k clusters are created by associating every} &\\
     \onslide<3->{observation with the nearest mean. The partitions here} & \\
     \onslide<3->{represent the Voronoi diagram generated by the
       means.} & \\
&     \onslide<3->{\includegraphics[width=0.15\textwidth]{K_Means_Example_Step_2.pdf}}\\
    \onslide<4->{3. The centroid of each of the k clusters becomes the
      new means.} & \\
&\onslide<4->{\includegraphics[width=0.15\textwidth]{K_Means_Example_Step_3.pdf}}\\
    \onslide<5->{Steps 2 and 3 are repeated until convergence has been
      reached.} & \\
&\onslide<5->{\includegraphics[width=0.15\textwidth]{K_Means_Example_Step_4.pdf}}\\
    \end{tabular}
  \end{center}
{\tiny Image credits: Wikipedia}
}
\end{frame}

\begin{frame}
\frametitle{Example: 5 class K-means }
\begin{columns}
\begin{column}{0.5\textwidth}
\begin{figure}[]
  \includegraphics[width=1.0\textwidth]{radio2-extract-3b.jpg}
\end{figure}
\end{column}
\begin{column}{0.5\textwidth}
\begin{figure}[]
  \includegraphics[width=1.0\textwidth]{kmeans-5-classes.png}
\end{figure}
\end{column}
\end{columns}
\end{frame}


\begin{frame}
  \frametitle{Hands On}
  \begin{enumerate}
  \item Monteverdi: Learning $\rightarrow$ KMeans Clustering
  \item Select the image to classify
  \item You can use only a subset of the pixels to perform the
    centroid estimation
  \item Select an appropriate number of classes for your image
  \item Set the number of iterations and the convergence threshold
  \item Run
  \end{enumerate}    
\end{frame}
\section[Supervised]{Supervised classification}
\label{sec:supervised}
\begin{frame}
  \frametitle{Supervised classification}
  \begin{itemize}
  \item Needs examples/ground truth
  \item Examples can have thematic labels
    \begin{itemize}
    \item Land-Use vs Land-Cover
    \end{itemize}
  \item Examples: neural networks, Bayesian maximum likelihood,
    Support Vector Machines
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Example: SVM}
\setbeamercovered{invisible}
{\tiny
\begin{center}
  \begin{tabular}{cc}
\onslide<2->{H3 (green) doesn't separate the 2 classes.} & \onslide<5->{Maximum-margin hyperplane and margins for a} \\
\onslide<3->{H1 (blue) does, with a small margin.} &  \onslide<5->{SVM trained with samples from two classes.}\\
\onslide<4->{H2 (red) with the maximum margin.} & \onslide<5->{Samples
  on the margin are called the support vectors.}\\
& \\
& \\
\includegraphics[width=0.3\textwidth]{Svm_separating_hyperplanes.png}
& \onslide<5->{\includegraphics[width=0.3\textwidth]{Svm_max_sep_hyperplane_with_margin.png}}\\
  \end{tabular}
\end{center}
{\tiny Image credits: Wikipedia}
}
\end{frame}

\begin{frame}
\frametitle{Example: 6 class SVM }
\framesubtitle{Water, vegetation, buildings, roads, clouds, shadows}
\begin{columns}
\begin{column}{0.5\textwidth}
\begin{figure}[]
  \includegraphics[width=1.0\textwidth]{radio2-extract-3b.jpg}
\end{figure}
\end{column}
\begin{column}{0.5\textwidth}
\begin{figure}[]
  \includegraphics[width=1.0\textwidth]{svm-6-classes.png}
\end{figure}
\end{column}
\end{columns}
\end{frame}


\begin{frame}
  \frametitle{Hands On}
  \begin{enumerate}
  \item Monteverdi: Learning $\rightarrow$ SVM Classification
  \item Select the image to classify
  \item Add a class
    \begin{itemize}
    \item You can give it a name, a color
    \end{itemize}
  \item Select samples for each class
    \begin{itemize}
    \item Draw polygons and use the {\em End Polygon} to close them
    \item You can assign polygons to either the training or the test
      sets; or you can use the random selection
    \end{itemize}
  \item Learn
  \item Validate: displays a confusion matrix and the classification accuracy
  \item Display results
  \end{enumerate}    
\end{frame}

\section[Object oriented]{Object oriented classification}
\label{sec:objectoriented}
\begin{frame}
  \frametitle{Object oriented classification}
  \begin{itemize}
  \item Pixels may not be the best way to describe the classes of interest
    \begin{itemize}
    \item shape, size, and other region-based characteristics may be
      more meaningful
    \end{itemize}
  \item We need to provide the classifier a set of regions
    \begin{itemize}
    \item Image segmentation
    \end{itemize}
  \item And their characteristics
    \begin{itemize}
    \item Compute features per region 
    \end{itemize}
  \item Since individual objects are meaningful, active learning can
    be implemented
    \begin{itemize}
    \item See presentation WE2.L06.2 {\em ``LAZY YET EFFICIENT LAND-COVER
      MAP GENERATION FOR HR OPTICAL IMAGES''}, Wednesday, July 28, 10:25
    - 12:05, by Julien Michel, Julien Malik and Jordi Inglada.
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{No hands on}
But a demo if the time allows it!
\end{frame}


\end{document}
